
'use server';

import { GoogleGenerativeAI } from '@google/generative-ai';
import { z } from 'zod';
import { dataUriToGenerativePart } from '@/lib/utils';

if (!process.env.GEMINI_API_KEY) {
  throw new Error('GEMINI_API_KEY is not set');
}

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({
  model: 'gemini-2.5-flash',
});


const ImageVerifierInputSchema = z.object({
  imageDataUri: z
    .string()
    .describe(
      "An image file, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
  language: z.string().describe('The language of the analysis, specified as a two-letter ISO 639-1 code (e.g., "en", "hi").'),
});

const ImageVerifierOutputSchema = z.object({
    verdict: z.enum(['Likely Authentic', 'Likely AI-Generated/Manipulated', 'Uncertain']).describe("The final judgment on the image's authenticity."),
    confidenceScore: z.number().describe("A score from 0-100 indicating the confidence in the verdict."),
    isAiGenerated: z.boolean().describe("Whether the image is likely generated by an AI model."),
    isManipulated: z.boolean().describe("Whether the image shows signs of digital manipulation (e.g., Photoshop)."),
    isMisleadingContext: z.boolean().describe("Whether the image might be used in a misleading context, even if authentic."),
    context: z.string().describe("An explanation of the image's potential context, including reverse image search findings or relevant news. This must be based on web search results."),
    report: z.string().describe("A detailed forensic report explaining the analysis, including details about artifacts, inconsistencies, or other findings."),
    textAnalysis: z.object({
        detectedText: z.string().optional().describe("Text detected within the image."),
        analysis: z.string().optional().describe("An analysis of the detected text for misinformation or manipulation."),
    }).optional(),
});

export type ImageVerifierInput = z.infer<typeof ImageVerifierInputSchema>;
export type ImageVerifierOutput = z.infer<typeof ImageVerifierOutputSchema>;


export async function imageVerifierAnalysis(input: ImageVerifierInput): Promise<ImageVerifierOutput> {
  const imagePart = dataUriToGenerativePart(input.imageDataUri);

  const prompt = `You are an expert digital image forensics analyst. Your task is to analyze an image to determine its authenticity and detect any signs of AI generation, digital manipulation, or misleading context. You have access to Google Search to find real-time information to ground your analysis.

Your final output MUST be only a single JSON object that strictly adheres to the provided schema. Do not include any other text, conversation, or markdown formatting.

You will perform the following analysis:
1.  **AI Generation Detection**: Analyze the image for artifacts characteristic of AI image synthesis (e.g., GANs, diffusion models). Look for tell-tale signs in textures, backgrounds, lighting, and anatomical details.
2.  **Manipulation Detection**: Look for evidence of digital alteration, such as cloning, splicing, or retouching. Analyze shadows, reflections, and perspectives for inconsistencies.
3.  **Contextual Analysis (Web Search)**: Use Google Search to perform a conceptual reverse image search. Determine the likely origin and context of the image. Is it being used out of context to spread misinformation? Find news articles, fact-checks, or other sources discussing the image.
4.  **Text Analysis (OCR)**: If there is text in the image, extract it and analyze it for misinformation.
5.  **Verdict and Confidence**: Provide a final verdict ('Likely Authentic', 'Likely AI-Generated/Manipulated', 'Uncertain') and a confidence score (0-100).
6.  **Reporting**: Generate a comprehensive report detailing your findings, including the forensic methods used and the reasoning for your verdict based on both the image analysis and web search results.

The output language for the report and analysis must be in the language specified by the user: ${input.language}.

Image for analysis is provided in the content.`;

  const result = await model.generateContent({
      contents: [{ role: 'user', parts: [imagePart, { text: prompt }] }],
      tools: [{ "google_search": {} }],
      generationConfig: {
        responseMimeType: "application/json",
      },
  });

  const response = result.response;
  const text = response.text();

  try {
      const parsed = JSON.parse(text);
      return ImageVerifierOutputSchema.parse(parsed);
  } catch (e) {
      console.error("Failed to parse LLM response:", text);
      throw new Error("The AI returned an invalid response format.");
  }
}
